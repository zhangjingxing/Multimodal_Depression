# Multimodal_Depression
A project using CNNs and RNNs to detect depression from multimodal data: speech recordings (acoustic features), transcripts (linguistic analysis), and facial features (action units for non-verbal cues). Integrates diverse data sources for accurate detection and mental health insights.
